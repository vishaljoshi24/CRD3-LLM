This repository is for the purposes of fine-tuning an LLM on the task of dialogue generation using the Critical Role Dungeons & Dragons Dataset (CRD3). Two pre-processing scripts have been added to allow for tokenization without and without the turns which include the character names and utterances. The tokenization time increases to about 2 hours, from approximately 10 minutes. 

